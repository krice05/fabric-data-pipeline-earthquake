# Beginner's Guide to Microsoft Fabric: Earthquake Data Pipeline

Welcome! This guide will walk you step-by-step through setting up a data pipeline using Microsoft Fabric. We’ll use an approach called the **medallion architecture** to organise earthquake data from raw to refined, making it easier for analysis. By the end of this guide, you’ll have an automated system that takes earthquake data from an API, processes it, and displays it in Power BI for easy insights—all updated daily!

### Business Case

Earthquake data is incredibly valuable for understanding seismic events and mitigating risks. Government agencies, research institutions, and insurance companies rely on up-to-date information to plan emergency responses and assess risks. With this automated pipeline, we ensure these stakeholders get the latest data in a way that’s easy to understand and ready to use, saving time and improving decision-making.

### Solution Overview

We're going to use **Microsoft Fabric** to build an end-to-end earthquake data pipeline using the **medallion architecture**. This involves:

- **Bronze Layer**: Collect raw earthquake data.
- **Silver Layer**: Transform it into a clean, structured format.
- **Gold Layer**: Enrich it with calculated fields for analysis.
- **Power BI**: Visualise the data interactively.
- **Data Factory**: Automate the entire process, ensuring up-to-date information daily.

![Data Engineering vs Software Engineering (2).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ae89901b-79f1-49d4-828c-c80d4912aeac/f1e7f09e-08ab-4756-b1ed-4341bd68bb8a/Data_Engineering_vs_Software_Engineering_(2).png)

### Medallion Architecture in Action

Let’s break down each layer:

1. **Bronze Layer (Raw Data Ingestion)**
    - **What It Does**: This layer is for storing raw data, exactly as we receive it.
    - **How We Do It**: Fetch earthquake data from an external API using a Python script and store it as **JSON files** in the Fabric Lakehouse.
    - **Why It’s Important**: This keeps the original data safe for audit or if you ever need to trace issues back to their source.
2. **Silver Layer (Data Transformation)**
    - **What It Does**: This layer takes the raw data and cleans it up for use.
    - **How We Do It**: Convert the **JSON files** into **Delta tables**. Here, we clean and filter the data—adding structured columns like event time, magnitude, and location.
    - **Why It’s Important**: This creates a clean, easy-to-use version of the data, ready for most reporting needs.
3. **Gold Layer (Data Enrichment)**
    - **What It Does**: This layer prepares data for high-quality analysis.
    - **How We Do It**: Use the Silver Layer data to create more meaningful information, like **country codes** and **significance classifications**. The final output is saved as a **Delta table**.
    - **Why It’s Important**: This gives you an enriched dataset that’s optimised for analysis, providing ready-to-use insights.
4. **Power BI Visualisation**
    - **What It Does**: Visualises the data to make it understandable at a glance.
    - **How We Do It**: Load the **Gold Layer** data into Power BI to create an interactive dashboard. Here, you can see trends and patterns in earthquake occurrences, like the number of events by country or the severity over time.
    - **Why It’s Important**: Visualisation is crucial for communicating complex data simply—making insights accessible to everyone.
5. **Orchestration with Data Factory**
    - **What It Does**: Automates the entire pipeline so that it runs every day.
    - **How We Do It**: Use **Data Factory** to set up a daily schedule, automating data collection, transformation, and enrichment.
    - **Why It’s Important**: Automation means you don’t need to manually update the data—ensuring stakeholders always have up-to-date information.

![diagram-export-09-12-2024-21_52_01.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ae89901b-79f1-49d4-828c-c80d4912aeac/a5c115f2-1865-4bb3-a37d-23c527580442/diagram-export-09-12-2024-21_52_01.png)

### Final Thoughts

By following this guide, you’ll implement a solid data pipeline from raw earthquake data to meaningful insights. This project uses the **medallion architecture** to make the data transformation process logical and organized, while **Power BI** makes it visually engaging and easy to understand. With **Data Factory**, you’ll automate everything, ensuring it keeps working for you on autopilot.
